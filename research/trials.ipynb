{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "927b4e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abhi\n"
     ]
    }
   ],
   "source": [
    "print(\"Abhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efa71585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c3a7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=\"pcsk_4ox7EQ_48i9bJpVkFXjr1qGS1xRptLkMiiMQtUTkxVEXiQDmohCXvBAfRNu7q9CtXvRTG5\"\n",
    "PINECONE_API_ENV=\"us-east-1-aws\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe4113",
   "metadata": {},
   "source": [
    "#extract data from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b2c1bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader=DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfb6a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf7b96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074f665",
   "metadata": {},
   "source": [
    "create test chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "697bd6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    \n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "532a5f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of my chunks: 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of my chunks:\",len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2d7f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "print(sentence_transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f84f38",
   "metadata": {},
   "source": [
    "Download Embeddding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a77094b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efc6382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\transformers\\modeling_utils.py:461: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "embeddings=download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61652a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d069ffa",
   "metadata": {},
   "source": [
    "venv name = mchatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c031cd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 384\n"
     ]
    }
   ],
   "source": [
    "query_result=embeddings.embed_query(\"hello world\")\n",
    "print(\"length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59ca7949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03447732329368591,\n",
       " 0.031023161485791206,\n",
       " 0.006734949070960283,\n",
       " 0.02610895223915577,\n",
       " -0.03936203941702843,\n",
       " -0.16030243039131165,\n",
       " 0.06692401319742203,\n",
       " -0.006441463716328144,\n",
       " -0.04745052009820938,\n",
       " 0.014758840203285217,\n",
       " 0.07087533921003342,\n",
       " 0.055527545511722565,\n",
       " 0.019193334504961967,\n",
       " -0.026251288130879402,\n",
       " -0.010109501890838146,\n",
       " -0.026940416544675827,\n",
       " 0.022307397797703743,\n",
       " -0.022226659581065178,\n",
       " -0.1496926099061966,\n",
       " -0.017493031919002533,\n",
       " 0.007676285691559315,\n",
       " 0.05435223504900932,\n",
       " 0.003254441311582923,\n",
       " 0.031725917011499405,\n",
       " -0.08462145179510117,\n",
       " -0.029405971989035606,\n",
       " 0.05159560590982437,\n",
       " 0.048124030232429504,\n",
       " -0.003314853413030505,\n",
       " -0.058279167860746384,\n",
       " 0.041969235986471176,\n",
       " 0.022210724651813507,\n",
       " 0.128188818693161,\n",
       " -0.022338958457112312,\n",
       " -0.011656282469630241,\n",
       " 0.06292833387851715,\n",
       " -0.032876305282115936,\n",
       " -0.09122604131698608,\n",
       " -0.03117535263299942,\n",
       " 0.0526995025575161,\n",
       " 0.047034818679094315,\n",
       " -0.0842030942440033,\n",
       " -0.030056176707148552,\n",
       " -0.02074483036994934,\n",
       " 0.009517780505120754,\n",
       " -0.003721755463629961,\n",
       " 0.00734330341219902,\n",
       " 0.039324358105659485,\n",
       " 0.09327403455972672,\n",
       " -0.003788584843277931,\n",
       " -0.05274210125207901,\n",
       " -0.0580582432448864,\n",
       " -0.006864365190267563,\n",
       " 0.00528319738805294,\n",
       " 0.08289297670125961,\n",
       " 0.019362760707736015,\n",
       " 0.006284492556005716,\n",
       " -0.01033081579953432,\n",
       " 0.009032378904521465,\n",
       " -0.03768372908234596,\n",
       " -0.04520607739686966,\n",
       " 0.024016305804252625,\n",
       " -0.006944130640476942,\n",
       " 0.013491630554199219,\n",
       " 0.10005498677492142,\n",
       " -0.071683868765831,\n",
       " -0.021695151925086975,\n",
       " 0.03161844238638878,\n",
       " -0.05163467675447464,\n",
       " -0.08224771171808243,\n",
       " -0.06569328904151917,\n",
       " -0.009895345196127892,\n",
       " 0.005816393531858921,\n",
       " 0.07355451583862305,\n",
       " -0.0340503454208374,\n",
       " 0.024886080995202065,\n",
       " 0.014488044194877148,\n",
       " 0.026457305997610092,\n",
       " 0.009656735695898533,\n",
       " 0.030217252671718597,\n",
       " 0.052803996950387955,\n",
       " -0.07535986602306366,\n",
       " 0.009897168725728989,\n",
       " 0.029836799949407578,\n",
       " 0.01755562052130699,\n",
       " 0.023091917857527733,\n",
       " 0.0019338353304192424,\n",
       " 0.0014001934323459864,\n",
       " -0.04717595875263214,\n",
       " -0.011194320395588875,\n",
       " -0.11420142650604248,\n",
       " -0.019811948761343956,\n",
       " 0.040266215801239014,\n",
       " 0.0021929885260760784,\n",
       " -0.07979220896959305,\n",
       " -0.025382332503795624,\n",
       " 0.09448295831680298,\n",
       " -0.028981056064367294,\n",
       " -0.14500252902507782,\n",
       " 0.230977401137352,\n",
       " 0.027731169015169144,\n",
       " 0.03211144730448723,\n",
       " 0.031065022572875023,\n",
       " 0.04283276945352554,\n",
       " 0.06423778831958771,\n",
       " 0.032163120806217194,\n",
       " -0.0048767393454909325,\n",
       " 0.05569945648312569,\n",
       " -0.037532366812229156,\n",
       " -0.02150552161037922,\n",
       " -0.028342651203274727,\n",
       " -0.02884693630039692,\n",
       " 0.0383530929684639,\n",
       " -0.017468685284256935,\n",
       " 0.05248529464006424,\n",
       " -0.07487601041793823,\n",
       " -0.031259749084711075,\n",
       " 0.021841609850525856,\n",
       " -0.03989572077989578,\n",
       " -0.008587049320340157,\n",
       " 0.02695658430457115,\n",
       " -0.04849548265337944,\n",
       " 0.011469886638224125,\n",
       " 0.02961818501353264,\n",
       " -0.02057221345603466,\n",
       " 0.013103866949677467,\n",
       " 0.02883344516158104,\n",
       " -3.1941972481122953e-33,\n",
       " 0.06478206813335419,\n",
       " -0.01813013292849064,\n",
       " 0.05178994685411453,\n",
       " 0.12198273837566376,\n",
       " 0.028780153021216393,\n",
       " 0.008722021244466305,\n",
       " -0.07052116841077805,\n",
       " -0.01690726727247238,\n",
       " 0.040739674121141434,\n",
       " 0.04211616516113281,\n",
       " 0.02544718235731125,\n",
       " 0.035746291279792786,\n",
       " -0.04914470762014389,\n",
       " 0.0021289971191436052,\n",
       " -0.015546534210443497,\n",
       " 0.05073054879903793,\n",
       " -0.0481853224337101,\n",
       " 0.035880621522665024,\n",
       " -0.0040670400485396385,\n",
       " 0.101724773645401,\n",
       " -0.05597008019685745,\n",
       " -0.01068102940917015,\n",
       " 0.011235786601901054,\n",
       " 0.09068656712770462,\n",
       " 0.004234420135617256,\n",
       " 0.03513865917921066,\n",
       " -0.009702865034341812,\n",
       " -0.09386514127254486,\n",
       " 0.09285557270050049,\n",
       " 0.008004928939044476,\n",
       " -0.007705375552177429,\n",
       " -0.05208668112754822,\n",
       " -0.01258799247443676,\n",
       " 0.0032669221982359886,\n",
       " 0.006013514939695597,\n",
       " 0.007581578101962805,\n",
       " 0.010517162270843983,\n",
       " -0.08634556829929352,\n",
       " -0.06987884640693665,\n",
       " -0.002533882623538375,\n",
       " -0.09097658842802048,\n",
       " 0.046887289732694626,\n",
       " 0.05207650735974312,\n",
       " 0.007193865720182657,\n",
       " 0.010903636924922466,\n",
       " -0.005229500588029623,\n",
       " 0.013937326148152351,\n",
       " 0.021968331187963486,\n",
       " 0.03420864790678024,\n",
       " 0.060224685817956924,\n",
       " 0.00011669372906908393,\n",
       " 0.014731966890394688,\n",
       " -0.07008924335241318,\n",
       " 0.028499020263552666,\n",
       " -0.027601715177297592,\n",
       " 0.010768423788249493,\n",
       " 0.03483095392584801,\n",
       " -0.02248789742588997,\n",
       " 0.009769000113010406,\n",
       " 0.07722778618335724,\n",
       " 0.021588360890746117,\n",
       " 0.11495620012283325,\n",
       " -0.0680011510848999,\n",
       " 0.023760991171002388,\n",
       " -0.01598397083580494,\n",
       " -0.01782698556780815,\n",
       " 0.06439489126205444,\n",
       " 0.03202573210000992,\n",
       " 0.050270285457372665,\n",
       " -0.005913708359003067,\n",
       " -0.03370801731944084,\n",
       " 0.01784026250243187,\n",
       " 0.016573341563344002,\n",
       " 0.06329653412103653,\n",
       " 0.0346771776676178,\n",
       " 0.04647350683808327,\n",
       " 0.09790616482496262,\n",
       " -0.006635493133217096,\n",
       " 0.025207066908478737,\n",
       " -0.07798831164836884,\n",
       " 0.016926486045122147,\n",
       " -0.0009457999840378761,\n",
       " 0.022471945732831955,\n",
       " -0.03825315460562706,\n",
       " 0.09570484608411789,\n",
       " -0.005350819323211908,\n",
       " 0.010469096712768078,\n",
       " -0.11524059623479843,\n",
       " -0.013262531720101833,\n",
       " -0.010709455236792564,\n",
       " -0.0831172838807106,\n",
       " 0.07327359169721603,\n",
       " 0.049392230808734894,\n",
       " -0.008994370698928833,\n",
       " -0.09584552049636841,\n",
       " 3.366147459724626e-33,\n",
       " 0.12493182718753815,\n",
       " 0.019349705427885056,\n",
       " -0.05822570621967316,\n",
       " -0.035988256335258484,\n",
       " -0.05074671283364296,\n",
       " -0.04566235840320587,\n",
       " -0.08260342478752136,\n",
       " 0.14819474518299103,\n",
       " -0.08842119574546814,\n",
       " 0.06027446314692497,\n",
       " 0.05103021115064621,\n",
       " 0.01030317135155201,\n",
       " 0.1412142813205719,\n",
       " 0.030813835561275482,\n",
       " 0.06103311479091644,\n",
       " -0.052851300686597824,\n",
       " 0.1366489678621292,\n",
       " 0.009189930744469166,\n",
       " -0.017325157299637794,\n",
       " -0.012848625890910625,\n",
       " -0.007995269261300564,\n",
       " -0.0509801059961319,\n",
       " -0.05235062539577484,\n",
       " 0.007593005895614624,\n",
       " -0.015166333876550198,\n",
       " 0.016960348933935165,\n",
       " 0.021270552650094032,\n",
       " 0.020558053627610207,\n",
       " -0.12002810090780258,\n",
       " 0.01446185726672411,\n",
       " 0.026759931817650795,\n",
       " 0.02533065341413021,\n",
       " -0.04275462403893471,\n",
       " 0.006768449675291777,\n",
       " -0.01445855014026165,\n",
       " 0.04526196047663689,\n",
       " -0.09147652983665466,\n",
       " -0.019439155235886574,\n",
       " -0.017833521589636803,\n",
       " -0.05491018667817116,\n",
       " -0.05264109745621681,\n",
       " -0.010459067299962044,\n",
       " -0.05201610177755356,\n",
       " 0.02089199796319008,\n",
       " -0.07997030764818192,\n",
       " -0.01211127545684576,\n",
       " -0.057731445878744125,\n",
       " 0.02317824587225914,\n",
       " -0.008031724020838737,\n",
       " -0.02598932944238186,\n",
       " -0.07995668798685074,\n",
       " -0.020728854462504387,\n",
       " 0.04881767928600311,\n",
       " -0.020389122888445854,\n",
       " -0.04917658120393753,\n",
       " 0.014159595593810081,\n",
       " -0.06362207233905792,\n",
       " -0.007807369343936443,\n",
       " 0.016431579366326332,\n",
       " -0.025682462379336357,\n",
       " 0.013381126336753368,\n",
       " 0.026248754933476448,\n",
       " 0.009978396818041801,\n",
       " 0.06322886794805527,\n",
       " 0.002672206610441208,\n",
       " -0.006582791917026043,\n",
       " 0.01663193479180336,\n",
       " 0.03236650303006172,\n",
       " 0.03794243931770325,\n",
       " -0.03637602552771568,\n",
       " -0.0069109173491597176,\n",
       " 0.00015967329090926796,\n",
       " -0.0016335470136255026,\n",
       " -0.027278177440166473,\n",
       " -0.028038080781698227,\n",
       " 0.04968143627047539,\n",
       " -0.028867192566394806,\n",
       " -0.0024180796463042498,\n",
       " 0.014774920418858528,\n",
       " 0.009764539077877998,\n",
       " 0.005797605495899916,\n",
       " 0.013486127369105816,\n",
       " 0.005567873362451792,\n",
       " 0.03722711652517319,\n",
       " 0.007232513278722763,\n",
       " 0.040156252682209015,\n",
       " 0.08150326460599899,\n",
       " 0.0719917044043541,\n",
       " -0.013056131079792976,\n",
       " -0.0428820475935936,\n",
       " -0.01101123820990324,\n",
       " 0.004897799808532,\n",
       " -0.009229699149727821,\n",
       " 0.03519148752093315,\n",
       " -0.051035039126873016,\n",
       " -1.571437557856825e-08,\n",
       " -0.08862442523241043,\n",
       " 0.02390924096107483,\n",
       " -0.0162387415766716,\n",
       " 0.031700488179922104,\n",
       " 0.027284223586320877,\n",
       " 0.05246886610984802,\n",
       " -0.04707092419266701,\n",
       " -0.05884747579693794,\n",
       " -0.06320814788341522,\n",
       " 0.04088856279850006,\n",
       " 0.04982796311378479,\n",
       " 0.10655167698860168,\n",
       " -0.07450230419635773,\n",
       " -0.012495440430939198,\n",
       " 0.01837066188454628,\n",
       " 0.03947407007217407,\n",
       " -0.024797869846224785,\n",
       " 0.01451626792550087,\n",
       " -0.03706919401884079,\n",
       " 0.020015742629766464,\n",
       " -4.856276063947007e-05,\n",
       " 0.009866593405604362,\n",
       " 0.02483878657221794,\n",
       " -0.05245813727378845,\n",
       " 0.029314152896404266,\n",
       " -0.08719191700220108,\n",
       " -0.014499741606414318,\n",
       " 0.02601904608309269,\n",
       " -0.01874636299908161,\n",
       " -0.07620518654584885,\n",
       " 0.03504335135221481,\n",
       " 0.10363949835300446,\n",
       " -0.028050482273101807,\n",
       " 0.012718183919787407,\n",
       " -0.0763254389166832,\n",
       " -0.01865231804549694,\n",
       " 0.02497672289609909,\n",
       " 0.0814453661441803,\n",
       " 0.06875886023044586,\n",
       " -0.06405661255121231,\n",
       " -0.08389388024806976,\n",
       " 0.06136234104633331,\n",
       " -0.03354554995894432,\n",
       " -0.10615333914756775,\n",
       " -0.040080539882183075,\n",
       " 0.03253019601106644,\n",
       " 0.07662484049797058,\n",
       " -0.07301618158817291,\n",
       " 0.00033755265758372843,\n",
       " -0.04087166115641594,\n",
       " -0.07578849047422409,\n",
       " 0.027527689933776855,\n",
       " 0.0746254101395607,\n",
       " 0.017717285081744194,\n",
       " 0.0912184864282608,\n",
       " 0.11022018641233444,\n",
       " 0.0005698095192201436,\n",
       " 0.051463402807712555,\n",
       " -0.014551329426467419,\n",
       " 0.033232033252716064,\n",
       " 0.023792287334799767,\n",
       " -0.022889861837029457,\n",
       " 0.03893750533461571,\n",
       " 0.03020685724914074]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb97c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'medical-chatbot' already exists. Connecting to it.\n",
      "Index object: <pinecone.data.index.Index object at 0x0000016DC9441C40>\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec, PodSpec # Make sure PodSpec is imported if you might use it\n",
    "\n",
    "# Initialize Pinecone\n",
    "# Replace with your actual API key and environment\n",
    "# Ensure your environment matches the region you plan to use if it's region-specific\n",
    "PINECONE_API_KEY = PINECONE_API_KEY\n",
    "PINECONE_API_ENV = PINECONE_API_ENV # e.g., \"us-east-1-aws\" or similar, check your dashboard\n",
    "\n",
    "pinecone = Pinecone(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_API_ENV\n",
    ")\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# Check if the index exists\n",
    "# pinecone.list_indexes() returns a list of dictionaries, so we need to check names\n",
    "existing_indexes = pinecone.list_indexes()\n",
    "existing_index_names = [idx['name'] for idx in existing_indexes]\n",
    "\n",
    "if index_name not in existing_index_names:\n",
    "    print(f\"Creating index '{index_name}'...\")\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # Ensure this matches your embedding model's dimension\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(cloud='aws', region='us-east-1') # Or your free-tier supported region\n",
    "    )\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists. Connecting to it.\")\n",
    "\n",
    "# Now you can connect to your index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# You can also add a small check to ensure it's ready, especially after creation\n",
    "# This is more relevant for Pod-based indexes, but good practice\n",
    "# try:\n",
    "#     # For Serverless, it should be ready almost immediately after creation call returns\n",
    "#     # For Pod, you might need to loop and check index.describe_index_stats() until 'ready'\n",
    "#     index.describe_index_stats()\n",
    "#     print(f\"Successfully connected to and can query index '{index_name}'.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error connecting to index '{index_name}': {e}\")\n",
    "\n",
    "print(f\"Index object: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc2da60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create/load Pinecone vectorstore for index 'medical-chatbot' using LangChain...\n",
      "Pinecone vectorstore created/loaded successfully using LangChain.\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import Pinecone as LangChainPinecone # Alias LangChain's Pinecone class\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document # Import if your text_chunks are Document objects\n",
    "\n",
    "# --- Assume these variables are already correctly defined and initialized from previous steps ---\n",
    "# PINECONE_API_KEY\n",
    "# PINECONE_API_ENV\n",
    "# index_name\n",
    "# text_chunks (e.g., list of Document objects with .page_content)\n",
    "# embeddings (your HuggingFaceEmbeddings or OpenAIEmbeddings instance)\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_4ox7EQ_48i9bJpVkFXjr1qGS1xRptLkMiiMQtUTkxVEXiQDmohCXvBAfRNu7q9CtXvRTG5\"\n",
    "os.environ[\"PINECONE_API_ENV\"] = \"your-env\"  # e.g., \"gcp-starter\"\n",
    "\n",
    "\n",
    "# Ensure the embedding model is initialized\n",
    "# This is usually done once at the top level\n",
    "# embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# --- Create/Load Vectorstore using LangChain's Pinecone integration ---\n",
    "print(f\"Attempting to create/load Pinecone vectorstore for index '{index_name}' using LangChain...\")\n",
    "\n",
    "try:\n",
    "    # Use LangChainPinecone (the aliased class from langchain_pinecone)\n",
    "    # This class handles embedding the text_chunks and upserting them to Pinecone\n",
    "    docsearch = LangChainPinecone.from_texts(\n",
    "        [t.page_content for t in text_chunks], # Ensure this extracts pure strings if text_chunks are Document objects\n",
    "        embeddings,\n",
    "        index_name=index_name,\n",
    "        # If your LangChainPinecone version requires it, you might also need to pass\n",
    "        # api_key=\"pcsk_4ox7EQ_48i9bJpVkFXjr1qGS1xRptLkMiiMQtUTkxVEXiQDmohCXvBAfRNu7q9CtXvRTG5\",\n",
    "        # environment=PINECONE_API_ENV\n",
    "        # However, it often picks these up from environment variables or the global pinecone.init()\n",
    "        # for the latest versions of langchain-pinecone.\n",
    "    )\n",
    "    print(\"Pinecone vectorstore created/loaded successfully using LangChain.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to create/load Pinecone vectorstore with LangChain: {e}\")\n",
    "    # Provide more specific guidance for common issues\n",
    "    print(\"Possible reasons:\")\n",
    "    print(\"1. 'text_chunks' format: Ensure it's a list of strings or list of Document objects with '.page_content'.\")\n",
    "    print(\"2. Environment/Kernel Issue: If 'AttributeError: from_texts...' persists, restart your Python kernel.\")\n",
    "    print(\"3. API Key/Environment: Double-check that PINECONE_API_KEY and PINECONE_API_ENV are correct and accessible.\")\n",
    "    print(\"4. Index Dimension Mismatch: The dimension of your embeddings must match the dimension of your Pinecone index.\")\n",
    "    raise # Re-raise the exception for full traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a4805fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Document(page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-\\nganisms and particles, like pollen or dust, by producing\\nspecific proteins called antibodies that are capable of\\nbinding to identifying molecules, or antigens, on the\\nforeign organisms. This reaction between antibody and\\nantigen sets off a series of reactions designed to protect\\nthe body from infection. Sometimes, this same series of'), Document(page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-\\nganisms and particles, like pollen or dust, by producing\\nspecific proteins called antibodies that are capable of\\nbinding to identifying molecules, or antigens, on the\\nforeign organisms. This reaction between antibody and\\nantigen sets off a series of reactions designed to protect\\nthe body from infection. Sometimes, this same series of'), Document(page_content='reaction. Allergic rhinitis is characterized by an itchy,\\nrunny nose, often with a scratchy or irritated throat due\\nto post-nasal drip. Inflammation of the thin membrane\\ncovering the eye (allergic conjunctivitis) causes redness,\\nirritation, and increased tearing in the eyes. Asthma caus-\\nes wheezing, coughing, and shortness of breath. Symp-\\ntoms of food allergies depend on the tissues most sensi-\\ntive to the allergen and whether the allergen spread sys-')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain_pinecone import Pinecone as LangChainPinecone\n",
    "\n",
    "docsearch = LangChainPinecone.from_existing_index(\n",
    "    index_name=\"medical-chatbot\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "query=\"What are Allergies\"\n",
    "\n",
    "docs=docsearch.similarity_search(query,k=3)\n",
    "\n",
    "print(\"Result:\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32db96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf1baf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs={\"prompt\":PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5f27395",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18729b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# Wrap Pinecone index as LangChain VectorStore\n",
    "vectorstore = Pinecone(\n",
    "    index=index,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    text_key=\"text\"\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,  # Must come from langchain.vectorstores.Pinecone\n",
    "    return_source_documents=True,  # ✅ fixed typo\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a142136",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt: \")\n",
    "    result=qa({\"query\":user_input})\n",
    "    print(\"Response: \",result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1f6607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
